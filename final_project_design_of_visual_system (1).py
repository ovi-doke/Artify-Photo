# -*- coding: utf-8 -*-
"""Final Project Design of Visual System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E4MsvuOEOJmaKKoxYC5D_HYIRnglTGbb
"""

# === SETUP ===
!pip install gdown --quiet
import gdown
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from skimage import color, filters
from PIL import Image, ImageDraw, ImageFont
import ipywidgets as widgets
from IPython.display import display, clear_output
import random
from google.colab import files
import scipy.ndimage
import tempfile

# === FILTER FUNCTIONS ===

# Utility: KMeans Color Quantization
# Step 1: Flatten and cluster RGB values into k dominant colors
# Step 2: Reconstruct clustered image from labels and cluster centers
def quantize_colors(img_rgb, k):
    flat = img_rgb.reshape(-1, 3)
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(flat)
    centers = np.uint8(kmeans.cluster_centers_)
    clustered = centers[labels].reshape(img_rgb.shape)
    return clustered, centers, labels

#--------------------------------------------------------------------------------------
# -------Impressionism Filter (KMeans Clustering + Stroke Rendering)-------------------
#--------------------------------------------------------------------------------------
def impressionism(img_rgb):
    # 1. Save the original image dimensions (width x height) for later resizing
    original_size = img_rgb.shape[:2][::-1]

    # 2. Resize the image to 300x300 for faster processing (lower computation)
    img_small = cv2.resize(img_rgb, (300, 300))

    # 3. Flatten image into a 2D array of RGB pixels and convert to float32 for KMeans
    pixels = img_small.reshape((-1, 3)).astype(np.float32)

    # 4. Apply KMeans clustering to extract 16 dominant colors from the image
    kmeans = KMeans(n_clusters=16, random_state=42)
    labels = kmeans.fit_predict(pixels)

    # 5. Convert the cluster centers to integers (color palette)
    palette = np.uint8(kmeans.cluster_centers_)

    # 6. Map each pixel to the nearest cluster color (reconstruct the image using the palette)
    quantized = palette[labels].reshape(img_small.shape)

    # 7. Create a canvas to overlay strokes on top of a blurred version of the original image
    background = cv2.GaussianBlur(img_small, (5, 5), 0)  # soft blurred background
    canvas = background.copy()  # initialize canvas with blurred image instead of white

    # 8. Define stroke behavior
    step = 3          # Distance between strokes (density)
    length = 5        # Length of each stroke
    thickness = 2     # Thickness of each stroke

    # 9. Loop over the image in steps to simulate brush strokes
    for y in range(0, img_small.shape[0], step):
        for x in range(0, img_small.shape[1], step):
            # Get the color for the current stroke from quantized image
            color = tuple(int(c) for c in quantized[y, x])

            # Generate a random stroke angle (Â±60 degrees)
            angle = random.uniform(-np.pi/3, np.pi/3)

            # Calculate stroke direction components
            dx = int(length * np.cos(angle))
            dy = int(length * np.sin(angle))

            # Apply slight jitter to simulate hand-painted imperfection
            jitter_x = x + random.randint(-1, 1)
            jitter_y = y + random.randint(-1, 1)

            # Define the start and end points of the stroke
            pt1 = (jitter_x, jitter_y)
            pt2 = (jitter_x + dx, jitter_y + dy)

            # Draw an anti-aliased colored line (stroke) on the canvas
            cv2.line(canvas, pt1, pt2, color, thickness, lineType=cv2.LINE_AA)

    # 10. Resize the painted canvas back to original image dimensions
    return cv2.resize(canvas, original_size)


#--------------------------------------------------------------------------------------
# Water Colour Painting Filter (Bilateral Filter + Canny Edges + HSV Adjustments)
#--------------------------------------------------------------------------------------
def watercolour(img_rgb):
    # 1. Apply bilateral filter to smooth the image while preserving edges.
    #    This mimics the blending of colors typical in watercolor paintings.
    smooth = cv2.bilateralFilter(img_rgb, d=25, sigmaColor=100, sigmaSpace=100)

    # 2. Convert the smoothed image to grayscale for edge detection.
    gray = cv2.cvtColor(smooth, cv2.COLOR_RGB2GRAY)

    # 3. Detect edges using Canny edge detector to outline details.
    edges = cv2.Canny(gray, 60, 120)

    # 4. Slightly thicken edges for a stronger watercolor outline effect.
    edges = cv2.dilate(edges, np.ones((2, 2), np.uint8), iterations=1)

    # 5. Convert edge map to 3-channel RGB and invert it to get white edges on black.
    edge_mask = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    edge_mask = (255 - edge_mask) * 0.8  # Slightly tone down intensity

    # 6. Blend the smooth base with the inverted edge mask for a soft painted effect.
    blended = cv2.addWeighted(smooth, 0.9, edge_mask.astype(np.uint8), 0.1, 0)

    # 7. Convert blended result to grayscale to analyze brightness for masking highlights.
    brightness = cv2.cvtColor(blended, cv2.COLOR_RGB2GRAY)

    # 8. Create a mask to preserve very bright areas (like highlights and whites).
    preserve_mask = brightness > 220
    preserve_mask = np.stack([preserve_mask]*3, axis=-1)  # Expand mask to 3 channels

    # 9. Shift color warmth slightly to give a natural painted tone (adds subtle warmth).
    warm_shift = np.array([10, 10, 5], dtype=np.uint8)
    toned = cv2.subtract(blended, warm_shift)

    # 10. Convert to HSV color space to manipulate saturation.
    hsv = cv2.cvtColor(toned, cv2.COLOR_RGB2HSV)

    # 11. Reduce saturation to desaturate and give a pastel/watercolor look.
    hsv[..., 1] = (hsv[..., 1] * 0.8).astype(np.uint8)

    # 12. Convert back to RGB.
    desaturated = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

    # 13. Preserve bright regions from the original image, and apply watercolor effect to the rest.
    return np.where(preserve_mask, img_rgb, desaturated)



#--------------------------------------------------------------------------------------
# Charcoal Sketch Filter (Inversion + Gaussian Blur + Blend)
#--------------------------------------------------------------------------------------
def charcoal(img_bgr):
    # 1. Convert input image to grayscale (charcoal is typically monochrome)
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)

    # 2. Invert grayscale image (light becomes dark and vice versa)
    #    Inversion helps create an "outline enhancement" when blurred
    inverted = 255 - gray

    # 3. Apply a Gaussian blur to the inverted image
    #    This simulates the smudging effect found in real charcoal drawings
    blur = scipy.ndimage.gaussian_filter(inverted, sigma=7)

    # 4. Blend the original grayscale with the blurred inversion
    #    This creates soft transitions while enhancing edges
    final = cv2.addWeighted(blur, 1, gray, 1, 0)

    # 5. Convert the result back to BGR format for consistency in pipelines
    return cv2.cvtColor(final, cv2.COLOR_GRAY2BGR)

#--------------------------------------------------------------------------------------
# Comic Book Filter (KMeans Clustering + Canny Edges + Halftone Dots)
#--------------------------------------------------------------------------------------
def comic(img_rgb, k=6):
    # 1. Reduce the number of colors using KMeans clustering
    clustered, _, _ = quantize_colors(img_rgb, k)

    # 2. Blend original image and clustered result to retain some texture
    #    60% simplified colors + 40% original for a bold-yet-detailed look
    vibrant = cv2.addWeighted(clustered, 0.6, img_rgb, 0.4, 0)

    # 3. Detect strong edges from the grayscale version of the original image
    edges = cv2.Canny(cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY), 110, 200)

    # 4. Invert the edges and apply them as a mask to the image
    #    This gives the bold black outlines typical in comic art
    base = cv2.bitwise_and(vibrant, cv2.cvtColor(cv2.bitwise_not(edges), cv2.COLOR_GRAY2RGB))

    # 5. Prepare a new layer to draw halftone-style dots
    gray_for_dots = cv2.cvtColor(vibrant, cv2.COLOR_RGB2GRAY)
    dot_layer = np.full_like(gray_for_dots, 255)  # start with a white background

    # 6. Iterate in a grid, placing black dots based on brightness
    for y in range(0, gray_for_dots.shape[0], 6):
        for x in range(0, gray_for_dots.shape[1], 6):
            # Darker areas get larger dots, lighter areas smaller ones
            radius = int(np.interp(255 - gray_for_dots[y, x], [0, 255], [1, 3]))
            cv2.circle(dot_layer, (x, y), radius, 0, -1)  # draw black dot

    # 7. Lightly blend the dot layer over the base comic image
    return cv2.addWeighted(base, 0.95, cv2.cvtColor(dot_layer, cv2.COLOR_GRAY2RGB), 0.05, 0)

#--------------------------------------------------------------------------------------
# Oil Canvas Filter (Bilateral Filter + KMeans + Sobel Edge Masking)
#--------------------------------------------------------------------------------------
def oil_canvas(img_rgb):
    # 1. Normalize image to range [0,1] for float processing
    A = img_rgb / 255.0

    # 2. Apply bilateral filter to each channel separately for smooth brushstroke-like effect
    #    Bilateral filter smooths while preserving edges, crucial for painterly appearance
    smooth = np.stack([
        cv2.bilateralFilter((A[:, :, v] * 255).astype(np.uint8), 12, 75, 10) / 255.0
        for v in range(3)
    ], axis=-1)

    # 3. Flatten the original image to a 2D array of RGB values for KMeans clustering
    flat = (A * 255).reshape(-1, 3).astype(np.float32)

    # 4. Perform color quantization using KMeans to reduce color palette (simulate paint dabs)
    kmeans = KMeans(n_clusters=16, random_state=42)
    labels = kmeans.fit_predict(flat)
    centers = kmeans.cluster_centers_ / 255.0  # Normalize again to [0,1] range

    # 5. Reconstruct quantized image using cluster labels
    quantized = centers[labels].reshape(A.shape)

    # 6. Convert image to grayscale to prepare for edge detection
    gray = color.rgb2gray(A)

    # 7. Detect edges using Sobel filter (returns gradient magnitude image)
    #    Invert and scale edge response to suppress strokes in edge areas
    edges = 1 - np.clip(filters.sobel(gray) * 2.0, 0, 1)  # Emphasize edges

    # 8. Repeat edges for 3 channels to apply masking across RGB
    edge_stack = np.dstack([edges] * 3)

    # 9. Blend the smoothed image and quantized colors (70% smooth, 30% quantized)
    #    This adds both fluidity (smooth) and artistic abstraction (quantized)
    blended = 0.7 * smooth + 0.3 * quantized

    # 10. Apply the edge mask to suppress details in strong edges (adds canvas texture)
    return np.clip(blended * edge_stack, 0, 1)



#--------------------------------------------------------------------------------------
# Word Art Filter (Font Size Mapping to Brightness)
#--------------------------------------------------------------------------------------
def word_art(img_path, phrase, font_path):
    try:
        # 1. Load the input image
        img = cv2.imread(img_path)

        # 2. Validate that the image is a proper color image
        if img is None or len(img.shape) != 3:
            raise ValueError("Invalid image format")

    except:
        # 3. Catch errors when reading image file
        raise ValueError("Unable to open image. Make sure it's a valid color image.")

    # 4. Convert the image to grayscale to measure brightness
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 5. Resize large images for performance and legibility
    max_dim = 300
    if max(gray.shape) > max_dim:
        scale = max_dim / max(gray.shape)
        gray = cv2.resize(gray, (int(gray.shape[1] * scale), int(gray.shape[0] * scale)))

    # 6. Get image dimensions
    h, w = gray.shape

    # 7. Create a large white canvas to draw the text art
    canvas = Image.new("L", (w * 14, h * 14), 255)  # grayscale, white background
    draw = ImageDraw.Draw(canvas)

    # 8. Prepare the phrase and index tracker
    words = phrase.upper().split()
    word_index = 0

    # 9. Loop over every 2 pixels to reduce density
    for y in range(0, h, 2):
        for x in range(0, w, 2):
            # 10. Get pixel brightness (0 = black, 255 = white)
            brightness = gray[y, x]

            # 11. Interpolate font size: darker pixel = bigger text
            font_size = int(np.interp(255 - brightness, [0, 255], [14, 28]))

            # 12. Load custom font if possible, else fallback to default
            try:
                font = ImageFont.truetype(font_path, size=font_size)
            except:
                font = ImageFont.load_default()

            # 13. Draw the next word in sequence
            draw.text((x * 14, y * 14), words[word_index % len(words)], font=font, fill=0)
            word_index += 1

    # 14. Return the finished word art canvas
    return canvas


#--------------------------------------------------------------------------------------
# Pointillism Filter (KMeans Clustering + Dot Stamping)
#--------------------------------------------------------------------------------------
def pointillism(img_rgb):
    # 1: Resize the image to 300x300 for faster computation and to reduce visual noise
    small = cv2.resize(img_rgb, (300, 300))

    # 2: Apply KMeans clustering to reduce the image to 16 dominant colors
    clustered, _, _ = quantize_colors(small, 16)

    # 3: Create a blank white canvas to draw the color dots (same size as small image)
    dot_img = np.ones_like(small) * 255

    # 4: Iterate over the image in a grid with step of 4 pixels
    for y in range(0, small.shape[0], 4):
        for x in range(0, small.shape[1], 4):
            # Step 5: Draw a small colored circle (dot) at each grid point
            cv2.circle(dot_img, (x, y), 2, clustered[y, x].tolist(), -1)

    # 6: Resize the dotted image back to the original input image size
    return cv2.resize(dot_img, img_rgb.shape[:2][::-1])


#--------------------------------------------------------------------------------------
# Andy Warhol Style Filter (KMeans Color Quantization + Manual Recoloring)
#--------------------------------------------------------------------------------------
def posterized_photo(img_rgb, k=4):
    # 1: Quantize the input image into 'k' dominant colors using KMeans clustering
    # Returns the simplified image, the color centers, and the labels
    posterized, centers, labels = quantize_colors(img_rgb, k)

    # 2: Define 4 different color maps (Warhol-style color schemes)
    color_maps = [
    [ [214, 108, 5],   [253, 219, 69],  [184, 3, 80],   [233, 231, 202] ],  # Quadrant 1
    [ [182, 6, 241],  [214, 129, 0],   [114, 54, 77],  [255, 246, 217] ],  # Quadrant 2
    [ [204, 0, 153], [200, 204, 9], [111, 92, 0]    ,  [230, 250, 230] ],  # Quadrant 3
    [ [0, 71, 171], [231, 147, 117],   [159, 50, 50],  [250, 200, 210] ]   # Quadrant 4
    ]

    outputs = []  # To store recolored versions

    # 3: For each Warhol color map
    for cmap in color_maps:
        # Create an empty canvas for the recolored output (same shape as input)
        recolored = np.zeros_like(posterized)

        # 4: For each of the k clustered colors, map them to new colors from the color map
        for i in range(k):
            mask = np.all(posterized == centers[i], axis=-1)  # Find pixels matching cluster center
            recolored[mask] = cmap[i % len(cmap)]             # Recolor using mapped color

        outputs.append(recolored)

    # 5: Arrange the 4 outputs in a 2x2 grid (Warhol-style collage)
    top = np.hstack((outputs[0], outputs[1]))     # Concatenate top row
    bottom = np.hstack((outputs[2], outputs[3]))  # Concatenate bottom row
    return np.vstack((top, bottom))               # Stack vertically to return final result


# === FILTER MAPPING ===
filters_dict = {
    "Impressionism": impressionism,
    "Water Colour Painting": watercolour,
    "Charcoal Sketch": lambda img: charcoal(cv2.cvtColor(img, cv2.COLOR_RGB2BGR)),
    "Comic Book": comic,
    "Oil on Canvas": lambda img: (oil_canvas(img) * 255).astype(np.uint8),
    "Word Art": None,
    "Pointillism": pointillism,
    "Andy Warhol Style": posterized_photo
}

# === DEFINE IMAGE FILES ===
download_folder = "art_inputs"
os.makedirs(download_folder, exist_ok=True)
file_ids = {
    "Marilyn_Monroe.jpg":"1KvUJnS1higxJU3195U7v5sTaxVWQdqCb",
    "Fruit.jpg": "1xlFlWO-i1gX4niMwaiJG40P2ioAxc9hk",
    "font.ttf": "1ee6DP6wvUYKSO_eEX6hYXPKnw5FD12mT",
    "GroupPhoto.jpg": "1IhibfqfNrsWH-tkT29JlOvw3MIwIfCHx",
    "SoloPhoto.jpg": "1HVnVr_ss_hk0SCzP2HS--6mFQF9YOmzV",
    "Tiger.png": "1jmFBA0hdb7y1L53lzf550cM4mqh3Ml0H"
}

for filename, file_id in file_ids.items():
    out_path = os.path.join(download_folder, filename)
    if not os.path.exists(out_path):
        gdown.download(f'https://drive.google.com/uc?id={file_id}', out_path, quiet=False)

# Manually ordered list of default images
preferred_order = [
    "Marilyn_Monroe.jpg",
    "Fruit.jpg",
    "GroupPhoto.jpg",
    "SoloPhoto.jpg",
    "Tiger.png"
]

# Only include files that actually exist (in case some failed to download)
image_files = [f for f in preferred_order if os.path.exists(os.path.join(download_folder, f))]


# === UI WIDGETS ===
choice_radio = widgets.RadioButtons(options=['Use Default Images', 'Upload Your Own Image'], description='Source:')
upload_widget = widgets.FileUpload(accept='image/*', multiple=False)
img_dropdown = widgets.Dropdown(options=image_files, description='Image:')
filter_dropdown = widgets.Dropdown(options=list(filters_dict.keys()), description='Filter:')
text_input = widgets.Text(description="Word/Phrase:")
warning_label = widgets.HTML(value="")
processing_label = widgets.HTML(value="")
run_button = widgets.Button(description="Run Filter", button_style='success')
download_button = widgets.Button(description="Download Result", button_style='info')
download_button.layout.margin = '12px 0 0 0'
download_button.layout.display = 'none'
download_output = widgets.Output()
download_output.layout.margin = '6px 0 12px 0'
out = widgets.Output()

# === DOWNLOAD HANDLER ===
latest_result_path = None

def save_and_offer_download(image_array, extension="png"):
    download_button.layout.display = 'inline-block'
    global latest_result_path
    _, temp_path = tempfile.mkstemp(suffix=f".{extension}")
    if image_array.ndim == 2:
        cv2.imwrite(temp_path, image_array)
    else:
        cv2.imwrite(temp_path, cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR))
    latest_result_path = temp_path
    with download_output:
        clear_output()
        if download_button.layout.display != 'none':
            print("ð Thanks for exploring my app! Happy Painting! ðï¸â¨")

def on_download_click(b):
    if latest_result_path and os.path.exists(latest_result_path):
        files.download(latest_result_path)
    else:
        with download_output:
            clear_output()
            print("â No result available to download yet.")

download_button.on_click(on_download_click)

# === VALIDATION ===
def validate_upload():
    if choice_radio.value == 'Upload Your Own Image' and not upload_widget.value:
        with out:
            clear_output()
            print("â Please upload an image to continue.")
        return False
    return True

# === UI LOGIC ===
def toggle_image_source(change):
    if choice_radio.value == 'Upload Your Own Image':
        upload_widget.layout.display = 'block'
        img_dropdown.layout.display = 'none'
    else:
        upload_widget.layout.display = 'none'
        img_dropdown.layout.display = 'block'

def toggle_wordart_fields(change):
    selected = filter_dropdown.value
    is_wordart = selected == "Word Art"
    is_warhol = selected == "Andy Warhol Style"
    text_input.layout.display = 'block' if is_wordart else 'none'
    if is_wordart:
        warning_label.value = ("<span style='color: orange; font-weight:bold;'>â ï¸ Word Art may take 2â3 minutes. Works best with portraits or images with prominent subjects. May not perform well on landscapes or abstract scenes.</span>")
    elif is_warhol:
        warning_label.value = ("<span style='color: orange; font-weight:bold;'>â ï¸ Andy Warhol Style works best with simple backgrounds and clear subjects like portraits or objects. Avoid complex landscapes.</span>")
    else:
        warning_label.value = ""

choice_radio.observe(toggle_image_source, names='value')
filter_dropdown.observe(toggle_wordart_fields, names='value')
toggle_image_source(None)
toggle_wordart_fields(None)

# === CALLBACK ===
def on_run_clicked(b):
    download_button.layout.display = 'none'  # Hide button on new run
    if not validate_upload():
        return
    with out:
        clear_output()
        processing_label.value = "<span style='color: orange;'>â³ Your image is being processed. Please sit tight and avoid clicking any buttons until it's done.</span>"
        if choice_radio.value == 'Upload Your Own Image' and upload_widget.value:
            uploaded_filename = list(upload_widget.value.keys())[0]
            content = upload_widget.value[uploaded_filename]['content']
            uploaded_path = os.path.join(download_folder, uploaded_filename)
            with open(uploaded_path, 'wb') as f:
                f.write(content)
            selected_path = uploaded_path
        else:
            selected_path = os.path.join(download_folder, img_dropdown.value)

        selected_filter = filter_dropdown.value

        if selected_filter == "Word Art":
            phrase = text_input.value.strip()
            font_path = os.path.join(download_folder, "font.ttf")
            if not phrase:
              processing_label.value = ""  # Clear the confusing "processing" message
              with out:
                  clear_output()
                  display(widgets.HTML("<span style='color: red; font-weight: bold;'>â Please enter a phrase.</span>"))
              return

            canvas = word_art(selected_path, phrase, font_path)
            img_bgr = cv2.imread(selected_path)
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            fig, axs = plt.subplots(1, 2, figsize=(12, 6))
            axs[0].imshow(img_rgb)
            axs[0].set_title("Original")
            axs[0].axis('off')
            axs[1].imshow(np.array(canvas.convert("L")), cmap='gray', vmin=0, vmax=255)

            axs[1].set_title("Word Art")
            axs[1].axis('off')
            plt.tight_layout()
            plt.show()
            save_and_offer_download(np.array(canvas))
        else:
            img_bgr = cv2.imread(selected_path)
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            result = filters_dict[selected_filter](img_rgb)
            fig, axs = plt.subplots(1, 2, figsize=(12, 6))
            axs[0].imshow(img_rgb)
            axs[0].set_title("Original")
            axs[0].axis('off')
            axs[1].imshow(result, cmap='gray' if len(result.shape) == 2 else None)
            axs[1].set_title(selected_filter)
            axs[1].axis('off')
            plt.tight_layout()
            plt.show()
            save_and_offer_download(result)
        processing_label.value = ""

run_button.on_click(on_run_clicked)

# === DISPLAY UI ===
display(widgets.VBox([
    choice_radio,
    widgets.HBox([upload_widget, img_dropdown]),
    filter_dropdown,
    text_input,
    warning_label,
    run_button,
    processing_label,
    out,
    download_button,
    download_output
]))

